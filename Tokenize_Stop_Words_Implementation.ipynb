{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tokenize_Stop_Words_Implementation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPrvxpY6zukEFb1JhMkDcDv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ztglLg5mg3a","executionInfo":{"status":"ok","timestamp":1649462163604,"user_tz":300,"elapsed":62495,"user":{"displayName":"Sterling Miller","userId":"05467034614136563673"}},"outputId":"982a1748-5053-4e0b-bdd2-6d9fd0f144c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [82.3 kB]\n","Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [952 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,133 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [918 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,831 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n","Get:25 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,694 kB]\n","Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [938 kB]\n","Get:27 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n","Get:28 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [884 kB]\n","Get:29 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.2 kB]\n","Get:30 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n","Fetched 15.6 MB in 6s (2,436 kB/s)\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.2.1'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"],"metadata":{"id":"33a6IiuTnMqy","executionInfo":{"status":"ok","timestamp":1649462349436,"user_tz":300,"elapsed":7095,"user":{"displayName":"Sterling Miller","userId":"05467034614136563673"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Now we'll learn to integrate Stop Words into our Natural Language Processing Tokenizer & DataFrames\n","\n","# Stop Words (words like \"and\", \"a\", \"the\", ...) are words that have negligible to no linguistic value in NLP"],"metadata":{"id":"IGG0oJ9LmqmV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a DataFrame that's already a list of words - For now let's skip the Tokenization step\n","\n","# Create DataFrame [list of words]\n","sentenceData = spark.createDataFrame([\n","                                      (0, [\"I\", \"like\", \"big\", \"butts\", \"and\", \"I\", \"cannot\", \"lie\"]),\n","                                      (1, [\"Big\", \"data\", \"is\", \"super\", \"powerful\"]),\n","                                      (2, [\"This\", \"is\", \"going\", \"to\", \"be\", \"Epic\"])\n","], [\"id\", \"raw\"])\n","\n","sentenceData.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wuB7SAWnhD4","executionInfo":{"status":"ok","timestamp":1649462573352,"user_tz":300,"elapsed":3135,"user":{"displayName":"Sterling Miller","userId":"05467034614136563673"}},"outputId":"887206c2-bd0b-40d4-c93d-8b58f8a5082a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------------+\n","|id |raw                                       |\n","+---+------------------------------------------+\n","|0  |[I, like, big, butts, and, I, cannot, lie]|\n","|1  |[Big, data, is, super, powerful]          |\n","|2  |[This, is, going, to, be, Epic]           |\n","+---+------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Now import the StopWordsRemover library\n","\n","# Import stop words remover library\n","from pyspark.ml.feature import StopWordsRemover"],"metadata":{"id":"Hayc9gbmoqXl","executionInfo":{"status":"ok","timestamp":1649462708624,"user_tz":300,"elapsed":120,"user":{"displayName":"Sterling Miller","userId":"05467034614136563673"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Now run the StopWordsRemover() function\n","\n","# the StopWordsRemover() function's arguments are names of the input column and the filtered output column \n","\n","\n","\n","# Run the Remover\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")"],"metadata":{"id":"Wfuqt74Po51z","executionInfo":{"status":"ok","timestamp":1649462948335,"user_tz":300,"elapsed":284,"user":{"displayName":"Sterling Miller","userId":"05467034614136563673"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Now transform the DataFrame by applying StopWordsRemover and display the result:\n","\n","# Transform and show data\n","remover.transform(sentenceData).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVs0GT3GpzPF","executionInfo":{"status":"ok","timestamp":1649462981507,"user_tz":300,"elapsed":1303,"user":{"displayName":"Sterling Miller","userId":"05467034614136563673"}},"outputId":"e6814e27-6cb8-4898-8152-ddc80d344703"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------------+----------------------------+\n","|id |raw                                       |filtered                    |\n","+---+------------------------------------------+----------------------------+\n","|0  |[I, like, big, butts, and, I, cannot, lie]|[like, big, butts, lie]     |\n","|1  |[Big, data, is, super, powerful]          |[Big, data, super, powerful]|\n","|2  |[This, is, going, to, be, Epic]           |[going, Epic]               |\n","+---+------------------------------------------+----------------------------+\n","\n"]}]}]}